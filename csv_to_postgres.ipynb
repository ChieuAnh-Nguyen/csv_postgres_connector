{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0a1f57f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'postgres_creds' from '/Users/chewynguyen/Desktop/csv_postgres_connector/postgres_creds.py'>"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import postgres_creds as cred\n",
    "# Since changes were made in cred and our ipynb can't see new changes, we use Importlib to reload the module\n",
    "import importlib\n",
    "importlib.reload(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host = cred.host,\n",
    "    user = cred.user,\n",
    "    password = cred.password,\n",
    "    database = cred.database)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Strategy\n",
    "\n",
    "1. create df_10 dataframe\n",
    "2. drop table, create table in DB with replaced object type, insert statement queries\n",
    "3. create insert into function\n",
    "4. Show table in DB funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Goal:\n",
    "\n",
    "1. Automate code: csv's can be imported without manually changing code\n",
    "2. Can upload multiple csv's at the same time\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "0. Create new folder in current directory, if it exists, pass \n",
    "1. Add csv's in current directory to a list\n",
    "2. Check cwd, if csv in cwd, move csv to new folder\n",
    "3. Create dictionary with csv name as key and df as value\n",
    "4. Look inside new folder and clean the csv names and their column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Create new folder in current directory for csvs that have been processed, if it exists, pass\n",
    "new_directory = \"imported_csv\"\n",
    "try:\n",
    "    os.mkdir(new_directory)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cities_test.csv', 'countriestest_10.csv']\n"
     ]
    }
   ],
   "source": [
    "# 1. add csv's in current directory to a list\n",
    "# re.sub(r'[^\\w\\.]', '_', csv) substitutes all non word and num characters\n",
    "csv_files = []\n",
    "for csv in os.listdir(os.getcwd()):\n",
    "    if '.csv' in csv:\n",
    "        old_csv_name = str(os.getcwd() + '/' + csv)\n",
    "        csv = re.sub(r'[^\\w\\.]', '_', csv).lower()\n",
    "        # 2. Check cwd, if csv in cwd, move csv to new folder\n",
    "        new_csv_name = str(os.getcwd() + '/' + new_directory + '/' + csv)\n",
    "        if os.path.isfile(new_csv_name):\n",
    "            print(\"The file already exists\")\n",
    "        else:\n",
    "            # Rename the file\n",
    "            os.rename(old_csv_name, new_csv_name)\n",
    "        csv_files.append(csv)\n",
    "\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cities_test.csv':                 city_ascii state_id            state_name  county_fips  \\\n",
      "city                                                                     \n",
      "New York          New York       NY              New York        36061   \n",
      "Los Angeles    Los Angeles       CA            California         6037   \n",
      "Chicago            Chicago       IL              Illinois        17031   \n",
      "Miami                Miami       FL               Florida        12086   \n",
      "Dallas              Dallas       TX                 Texas        48113   \n",
      "Philadelphia  Philadelphia       PA          Pennsylvania        42101   \n",
      "Houston            Houston       TX                 Texas        48201   \n",
      "Atlanta            Atlanta       GA               Georgia        13121   \n",
      "Washington      Washington       DC  District of Columbia        11001   \n",
      "\n",
      "                       county_name      lat       lng  population  density  \\\n",
      "city                                                                         \n",
      "New York                  New York  40.6943  -73.9249    18713220    10715   \n",
      "Los Angeles            Los Angeles  34.1139 -118.4068    12750807     3276   \n",
      "Chicago                       Cook  41.8373  -87.6862     8604203     4574   \n",
      "Miami                   Miami-Dade  25.7839  -80.2102     6445545     5019   \n",
      "Dallas                      Dallas  32.7936  -96.7662     5743938     1526   \n",
      "Philadelphia          Philadelphia  40.0077  -75.1339     5649300     4554   \n",
      "Houston                     Harris  29.7863  -95.3889     5464251     1399   \n",
      "Atlanta                     Fulton  33.7627  -84.4224     5449398     1441   \n",
      "Washington    District of Columbia  38.9047  -77.0163     5379184     4457   \n",
      "\n",
      "               source  military  incorporated             timezone  ranking  \\\n",
      "city                                                                          \n",
      "New York      polygon     False          True     America/New_York        1   \n",
      "Los Angeles   polygon     False          True  America/Los_Angeles        1   \n",
      "Chicago       polygon     False          True      America/Chicago        1   \n",
      "Miami         polygon     False          True     America/New_York        1   \n",
      "Dallas        polygon     False          True      America/Chicago        1   \n",
      "Philadelphia  polygon     False          True     America/New_York        1   \n",
      "Houston       polygon     False          True      America/Chicago        1   \n",
      "Atlanta       polygon     False          True     America/New_York        1   \n",
      "Washington    polygon     False          True     America/New_York        1   \n",
      "\n",
      "                                                           zips          id  \n",
      "city                                                                         \n",
      "New York      11229 11226 11225 11224 11222 11221 11220 1138...  1840034016  \n",
      "Los Angeles   90291 90293 90292 91316 91311 90037 90031 9000...  1840020491  \n",
      "Chicago       60018 60649 60641 60640 60643 60642 60645 6064...  1840000494  \n",
      "Miami         33129 33125 33126 33127 33128 33149 33144 3314...  1840015149  \n",
      "Dallas        75287 75098 75233 75254 75251 75252 75253 7503...  1840019440  \n",
      "Philadelphia  19154 19151 19150 19153 19152 19102 19103 1910...  1840000673  \n",
      "Houston       77069 77068 77061 77060 77063 77062 77065 7706...  1840020925  \n",
      "Atlanta       30334 30331 30332 30309 30308 30305 30307 3030...  1840013660  \n",
      "Washington    20010 20011 20012 20015 20228 20520 20307 2041...  1840006060  , 'countriestest_10.csv':          Date      Country  Confirmed  Recovered  Deaths\n",
      "0  2020-01-22  Afghanistan          0          0       0\n",
      "1  2020-01-23  Afghanistan          0          0       0\n",
      "2  2020-01-24  Afghanistan          0          0       0\n",
      "3  2020-01-25  Afghanistan          0          0       0\n",
      "4  2020-01-26  Afghanistan          0          0       0\n",
      "5  2020-01-27  Afghanistan          0          0       0\n",
      "6  2020-01-28  Afghanistan          0          0       0\n",
      "7  2020-01-29  Afghanistan          0          0       0\n",
      "8  2020-01-30  Afghanistan          0          0       0\n",
      "9  2020-01-31  Afghanistan          0          0       0}\n"
     ]
    }
   ],
   "source": [
    "# automating read csv to df\n",
    "# 3. Create dictionary with csv name as key and df as value\n",
    "df = {}\n",
    "for csv in csv_files:\n",
    "    csv_path = str(os.getcwd() + '/' + new_directory + '/' + csv)\n",
    "    df[csv] = pd.read_csv(csv_path, index_col = 0)\n",
    "\n",
    "# remember to drop all csv from csv_files after done working with it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS cities_test\n",
      "CREATE TABLE cities_test (city_ascii varchar(255), state_id varchar(255), state_name varchar(255), county_fips int, county_name varchar(255), lat float, lng float, population int, density int, source varchar(255), military boolean, incorporated boolean, timezone varchar(255), ranking int, zips varchar(255), id int)\n",
      "DROP TABLE IF EXISTS countriestest_10\n",
      "CREATE TABLE countriestest_10 (date varchar(255), country varchar(255), confirmed int, recovered int, deaths int)\n"
     ]
    }
   ],
   "source": [
    "# 4. Name already clean but look inside new folder and their column names\n",
    "\n",
    "for key in df:\n",
    "    dataframe = df[key]\n",
    "    clean_csv_name = re.sub(r'[^\\w\\.]', '_', key).lower()\n",
    "    dataframe.columns = [re.sub(r'[^\\w\\.]', '_', column_name).lower() for column_name in dataframe.columns]\n",
    "\n",
    "# Creates DB table name\n",
    "    db_table_name = key.split('.')[0]\n",
    "\n",
    "\n",
    "# Replacing pd datatypes with sql datatypes\n",
    "    replacements = {\n",
    "        'timedelta64[ns]': 'varchar(255)',\n",
    "        'object': 'varchar(255)',\n",
    "        'float64': 'float',\n",
    "        'bool': 'boolean',\n",
    "        'int64': 'int',\n",
    "        'datetime64': 'timestamp'}\n",
    "    replaced_dtypes = dataframe.dtypes.replace(replacements)\n",
    "    # table schema\n",
    "    column_dtype = \", \".join(\"{} {}\".format(col_name, dtype) for (col_name, dtype) in zip(dataframe.columns, replaced_dtypes))\n",
    "\n",
    "\n",
    "    # 2. create queries\n",
    "    drop_table = 'DROP TABLE IF EXISTS ' + db_table_name\n",
    "    create_table = 'CREATE TABLE ' + db_table_name + \" (\" + column_dtype + \")\"\n",
    "    # insert_into_table = 'INSERT INTO countries_aggregated (Date,Country,Confirmed,Recovered,Deaths) VALUES (%s,%s,%s,%s,%s)'\n",
    "    # select_table = 'SELECT * FROM ' + db_table_name\n",
    "\n",
    "    # cursor.execute(drop_table)\n",
    "    # cursor.execute(create_table)\n",
    "    # # 3. create insert into function\n",
    "    # for index, row in df.iterrows():\n",
    "    #     cursor.execute(insert_into_table,row)\n",
    "    # conn.commit()\n",
    "\n",
    "    # # 4. Show table in DB\n",
    "    # cursor.execute(select_table)\n",
    "    # for each in cursor:\n",
    "    #     print(each)\n",
    "    print(drop_table)\n",
    "    print(create_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
